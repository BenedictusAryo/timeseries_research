{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "keras = tf.keras\r\n",
    "import numpy as np \r\n",
    "import pandas as pd \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesGenerator(object):\r\n",
    "    \"\"\"Utility class for generating batches of temporal data.\r\n",
    "    This class takes in a sequence of data-points gathered at\r\n",
    "    equal intervals, along with time series parameters such as\r\n",
    "    stride, length of history, etc., to produce batches for\r\n",
    "    training/validation.\r\n",
    "    # Arguments\r\n",
    "        data: Indexable generator (such as list or Numpy array)\r\n",
    "            containing consecutive data points (timesteps).\r\n",
    "            The data should be at 2D, and axis 0 is expected\r\n",
    "            to be the time dimension.\r\n",
    "        targets: Targets corresponding to timesteps in `data`.\r\n",
    "            It should have same length as `data`.\r\n",
    "        length: Length of the output sequences (in number of timesteps).\r\n",
    "        sampling_rate: Period between successive individual timesteps\r\n",
    "            within sequences. For rate `r`, timesteps\r\n",
    "            `data[i]`, `data[i-r]`, ... `data[i - length]`\r\n",
    "            are used for create a sample sequence.\r\n",
    "        stride: Period between successive output sequences.\r\n",
    "            For stride `s`, consecutive output samples would\r\n",
    "            be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\r\n",
    "        start_index: Data points earlier than `start_index` will not be used\r\n",
    "            in the output sequences. This is useful to reserve part of the\r\n",
    "            data for test or validation.\r\n",
    "        end_index: Data points later than `end_index` will not be used\r\n",
    "            in the output sequences. This is useful to reserve part of the\r\n",
    "            data for test or validation.\r\n",
    "        shuffle: Whether to shuffle output samples,\r\n",
    "            or instead draw them in chronological order.\r\n",
    "        reverse: Boolean: if `true`, timesteps in each output sample will be\r\n",
    "            in reverse chronological order.\r\n",
    "        batch_size: Number of timeseries samples in each batch\r\n",
    "            (except maybe the last one).\r\n",
    "    # Returns\r\n",
    "        A [Sequence](/utils/#sequence) instance.\r\n",
    "    # Examples\r\n",
    "    ```python\r\n",
    "    from keras.preprocessing.sequence import TimeseriesGenerator\r\n",
    "    import numpy as np\r\n",
    "    data = np.array([[i] for i in range(50)])\r\n",
    "    targets = np.array([[i] for i in range(50)])\r\n",
    "    data_gen = TimeseriesGenerator(data, targets,\r\n",
    "                                   length=10, sampling_rate=2,\r\n",
    "                                   batch_size=2)\r\n",
    "    assert len(data_gen) == 20\r\n",
    "    batch_0 = data_gen[0]\r\n",
    "    x, y = batch_0\r\n",
    "    assert np.array_equal(x,\r\n",
    "                          np.array([[[0], [2], [4], [6], [8]],\r\n",
    "                                    [[1], [3], [5], [7], [9]]]))\r\n",
    "    assert np.array_equal(y,\r\n",
    "                          np.array([[10], [11]]))\r\n",
    "    ```\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, data, targets,\r\n",
    "                 length,\r\n",
    "                 sampling_rate=1,\r\n",
    "                 length_output=1,\r\n",
    "                 sampling_rate_output=1,\r\n",
    "                 stride=1,\r\n",
    "                 start_index=0,\r\n",
    "                 end_index=None,\r\n",
    "                 shuffle=False,\r\n",
    "                 reverse=False,\r\n",
    "                 batch_size=sys.maxsize,\r\n",
    "                 augmentation=0,\r\n",
    "                 overlap=0):\r\n",
    "\r\n",
    "        if len(data) != len(targets):\r\n",
    "            raise ValueError('Data and targets have to be' +\r\n",
    "                             ' of same length. '\r\n",
    "                             'Data length is {}'.format(len(data)) +\r\n",
    "                             ' while target length is {}'.format(len(targets)))\r\n",
    "\r\n",
    "        self.data = data\r\n",
    "        self.targets = targets\r\n",
    "        self.length = length\r\n",
    "        self.length_output = length_output\r\n",
    "        self.sampling_rate = sampling_rate\r\n",
    "        self.sampling_rate_output = sampling_rate_output\r\n",
    "        self.stride = stride\r\n",
    "        self.start_index = start_index\r\n",
    "        if end_index is None:\r\n",
    "            end_index = len(data) - 1\r\n",
    "        self.end_index = end_index\r\n",
    "        self.shuffle = shuffle\r\n",
    "        self.reverse = reverse\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.augmentation = augmentation\r\n",
    "        self.overlap = overlap\r\n",
    "\r\n",
    "        # the check below the way it was before didn't make sense since the generator might be used to represent only past data too.\r\n",
    "        # Adding one to the right side of the comparison for that very reason!\r\n",
    "        if self.start_index + length > self.end_index + 1:\r\n",
    "            raise ValueError('`start_index+length=%i > end_index=%i` '\r\n",
    "                             'is disallowed, as no part of the sequence '\r\n",
    "                             'would be left to be used as current step.'\r\n",
    "                             % (self.start_index + length, self.end_index))\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        if self.batch_size == sys.maxsize:\r\n",
    "            return 1\r\n",
    "        return int((self.end_index - self.start_index - self.length + 1 - self.length_output + self.overlap + self.augmentation)//(self.batch_size * self.stride)) + 1\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        i = self.start_index + self.length\r\n",
    "        if index != 0:\r\n",
    "            i = i + self.batch_size * self.stride * index\r\n",
    "        rows = np.arange(\r\n",
    "            i,\r\n",
    "            min(\r\n",
    "                i + self.batch_size * self.stride,\r\n",
    "                self.end_index + 2 - self.length_output\r\n",
    "            ),\r\n",
    "            self.stride\r\n",
    "        )\r\n",
    "        if self.shuffle:\r\n",
    "            np.random.shuffle(rows)\r\n",
    "\r\n",
    "        samples = np.stack([self.data[row - self.length:row:self.sampling_rate]\r\n",
    "                            for row in rows])\r\n",
    "        if self.augmentation:\r\n",
    "            augmented_rows = [row + np.random.randint(-self.augmentation, self.augmentation+1) for row in rows]\r\n",
    "        else:\r\n",
    "            augmented_rows = rows\r\n",
    "        targets = np.stack([\r\n",
    "            self.targets[\r\n",
    "                row - self.overlap : row + self.length_output : self.sampling_rate_output\r\n",
    "            ] for row in augmented_rows\r\n",
    "        ])\r\n",
    "\r\n",
    "        if targets.shape[1] == 1:\r\n",
    "            targets = targets.squeeze(1)\r\n",
    "\r\n",
    "        if self.reverse:\r\n",
    "            return samples[:, ::-1, ...], targets\r\n",
    "        return samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[i, (j+1)*10] for i,j in zip(range(50),range(50))])\r\n",
    "targets = np.array([[i] for i in range(50)])\r\n",
    "\r\n",
    "start_index = 0\r\n",
    "end_index = len(data) - 1\r\n",
    "lags=5\r\n",
    "sampling_rate=1\r\n",
    "batch_size=2\r\n",
    "output_length=2\r\n",
    "stride=1\r\n",
    "\r\n",
    "data_gen = TimeseriesGenerator(data, targets,\r\n",
    "                                   length=lags, sampling_rate=sampling_rate,\r\n",
    "                                   batch_size=batch_size, length_output=output_length, stride=stride)\r\n",
    "batch_0 = data_gen[0]                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0, 10],\n",
       "         [ 1, 20],\n",
       "         [ 2, 30],\n",
       "         [ 3, 40],\n",
       "         [ 4, 50]],\n",
       " \n",
       "        [[ 1, 20],\n",
       "         [ 2, 30],\n",
       "         [ 3, 40],\n",
       "         [ 4, 50],\n",
       "         [ 5, 60]]]),\n",
       " array([[[5],\n",
       "         [6]],\n",
       " \n",
       "        [[6],\n",
       "         [7]]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = start_index + lags\r\n",
    "\r\n",
    "rows = np.arange(\r\n",
    "    i,\r\n",
    "    min(\r\n",
    "        i + batch_size * stride,\r\n",
    "        end_index + 2 - output_length\r\n",
    "    ),\r\n",
    "    stride\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0, 10],\n",
       "        [ 1, 20],\n",
       "        [ 2, 30],\n",
       "        [ 3, 40],\n",
       "        [ 4, 50]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.stack([data[row - lags:row:sampling_rate]\r\n",
    "                            for row in rows])\r\n",
    "samples                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0, 10],\n",
       "        [ 2, 30],\n",
       "        [ 4, 50]])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data[row - lags:row:2]for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52035e4d146f99c150422bfac8e07f32a30b89a60d9dd60756d600c4b026426f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}