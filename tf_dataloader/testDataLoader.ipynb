{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "keras = tf.keras\r\n",
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesGenerator(keras.utils.Sequence):\r\n",
    "    \"\"\"Utility class for generating batches of temporal data.\r\n",
    "    This class takes in a sequence of data-points gathered at\r\n",
    "    equal intervals, along with time series parameters such as\r\n",
    "    stride, length of history, etc., to produce batches for\r\n",
    "    training/validation.\r\n",
    "    # Arguments\r\n",
    "        data: Indexable generator (such as list or Numpy array)\r\n",
    "            containing consecutive data points (timesteps).\r\n",
    "            The data should be at 2D, and axis 0 is expected\r\n",
    "            to be the time dimension.\r\n",
    "        targets: Targets corresponding to timesteps in `data`.\r\n",
    "            It should have same length as `data`.\r\n",
    "        length: Length of the output sequences (in number of timesteps).\r\n",
    "        sampling_rate: Period between successive individual timesteps\r\n",
    "            within sequences. For rate `r`, timesteps\r\n",
    "            `data[i]`, `data[i-r]`, ... `data[i - length]`\r\n",
    "            are used for create a sample sequence.\r\n",
    "        stride: Period between successive output sequences.\r\n",
    "            For stride `s`, consecutive output samples would\r\n",
    "            be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\r\n",
    "        start_index: Data points earlier than `start_index` will not be used\r\n",
    "            in the output sequences. This is useful to reserve part of the\r\n",
    "            data for test or validation.\r\n",
    "        end_index: Data points later than `end_index` will not be used\r\n",
    "            in the output sequences. This is useful to reserve part of the\r\n",
    "            data for test or validation.\r\n",
    "        shuffle: Whether to shuffle output samples,\r\n",
    "            or instead draw them in chronological order.\r\n",
    "        reverse: Boolean: if `true`, timesteps in each output sample will be\r\n",
    "            in reverse chronological order.\r\n",
    "        batch_size: Number of timeseries samples in each batch\r\n",
    "            (except maybe the last one).\r\n",
    "        overlap: Number of overlap allowed in target data\r\n",
    "        gap: Sequence Gap of target data\r\n",
    "    # Returns\r\n",
    "        A [Sequence](/utils/#sequence) instance.\r\n",
    "    # Examples\r\n",
    "    ```python\r\n",
    "    from keras.preprocessing.sequence import TimeseriesGenerator\r\n",
    "    import numpy as np\r\n",
    "    data = np.array([[i] for i in range(50)])\r\n",
    "    targets = np.array([[i] for i in range(50)])\r\n",
    "    data_gen = TimeseriesGenerator(data, targets,\r\n",
    "                                   length=10, sampling_rate=2,\r\n",
    "                                   batch_size=2)\r\n",
    "    assert len(data_gen) == 20\r\n",
    "    batch_0 = data_gen[0]\r\n",
    "    x, y = batch_0\r\n",
    "    assert np.array_equal(x,\r\n",
    "                          np.array([[[0], [2], [4], [6], [8]],\r\n",
    "                                    [[1], [3], [5], [7], [9]]]))\r\n",
    "    assert np.array_equal(y,\r\n",
    "                          np.array([[10], [11]]))\r\n",
    "    ```\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, data, targets,\r\n",
    "                 length,\r\n",
    "                 sampling_rate=1,\r\n",
    "                 length_output=1,\r\n",
    "                 sampling_rate_output=1,\r\n",
    "                 stride=1,\r\n",
    "                 start_index=0,\r\n",
    "                 end_index=None,\r\n",
    "                 shuffle=False,\r\n",
    "                 reverse=False,\r\n",
    "                 batch_size=sys.maxsize,\r\n",
    "                 augmentation=0,\r\n",
    "                 overlap=0,\r\n",
    "                 gap=0):\r\n",
    "\r\n",
    "        if len(data) != len(targets):\r\n",
    "            raise ValueError('Data and targets have to be' +\r\n",
    "                             ' of same length. '\r\n",
    "                             'Data length is {}'.format(len(data)) +\r\n",
    "                             ' while target length is {}'.format(len(targets)))\r\n",
    "\r\n",
    "        self.data = data\r\n",
    "        self.targets = targets\r\n",
    "        self.length = length\r\n",
    "        self.length_output = length_output\r\n",
    "        self.sampling_rate = sampling_rate\r\n",
    "        self.sampling_rate_output = sampling_rate_output\r\n",
    "        self.stride = stride\r\n",
    "        self.start_index = start_index\r\n",
    "        if end_index is None:\r\n",
    "            end_index = len(data) - 1\r\n",
    "        self.end_index = end_index\r\n",
    "        self.shuffle = shuffle\r\n",
    "        self.reverse = reverse\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.augmentation = augmentation\r\n",
    "        self.overlap = overlap\r\n",
    "        self.gap = gap\r\n",
    "\r\n",
    "        # the check below the way it was before didn't make sense since the generator might be used to represent only past data too.\r\n",
    "        # Adding one to the right side of the comparison for that very reason!\r\n",
    "        if self.start_index + length > self.end_index + 1:\r\n",
    "            raise ValueError('`start_index+length=%i > end_index=%i` '\r\n",
    "                             'is disallowed, as no part of the sequence '\r\n",
    "                             'would be left to be used as current step.'\r\n",
    "                             % (self.start_index + length, self.end_index))\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        if self.batch_size == sys.maxsize:\r\n",
    "            return 1\r\n",
    "        return int((self.end_index - self.start_index - self.length + 1 - self.length_output + self.overlap + self.augmentation - self.gap)//(self.batch_size * self.stride)) + 1\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        i = self.start_index + self.length\r\n",
    "        if index != 0:\r\n",
    "            i = i + self.batch_size * self.stride * index\r\n",
    "        rows = np.arange(\r\n",
    "            i,\r\n",
    "            min(\r\n",
    "                i + self.batch_size * self.stride,\r\n",
    "                self.end_index + 2 - self.length_output\r\n",
    "            ),\r\n",
    "            self.stride\r\n",
    "        )\r\n",
    "        if self.shuffle:\r\n",
    "            np.random.shuffle(rows)\r\n",
    "\r\n",
    "        samples = np.stack([self.data[row - self.length:row:self.sampling_rate]\r\n",
    "                            for row in rows])\r\n",
    "        if self.augmentation:\r\n",
    "            augmented_rows = [row + np.random.randint(-self.augmentation, self.augmentation+1) for row in rows]\r\n",
    "        else:\r\n",
    "            augmented_rows = rows\r\n",
    "        targets = np.stack([\r\n",
    "            self.targets[\r\n",
    "                row - self.overlap + self.gap: row + self.length_output + self.gap: self.sampling_rate_output\r\n",
    "            ] for row in augmented_rows\r\n",
    "        ])\r\n",
    "\r\n",
    "        if targets.shape[1] == 1:\r\n",
    "            targets = targets.squeeze(1)\r\n",
    "\r\n",
    "        if self.reverse:\r\n",
    "            return samples[:, ::-1, ...], targets\r\n",
    "        return samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0, 10],\n",
       "        [ 1, 20],\n",
       "        [ 2, 30],\n",
       "        [ 3, 40],\n",
       "        [ 4, 50],\n",
       "        [ 5, 60]]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([data[row - lags:row + gap:sampling_rate]\r\n",
    "                            for row in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[i, (j+1)*10] for i,j in zip(range(50),range(50))])\r\n",
    "target = np.array([[i] for i in range(50)])\r\n",
    "\r\n",
    "start_index = 0\r\n",
    "end_index = len(data) - 1\r\n",
    "lags=5\r\n",
    "sampling_rate=1\r\n",
    "batch_size=1\r\n",
    "output_length=1\r\n",
    "stride=1\r\n",
    "sampling_rate_output=1\r\n",
    "overlap=0\r\n",
    "gap=1\r\n",
    "\r\n",
    "data_gen = TimeseriesGenerator(data, target,\r\n",
    "                                length=lags, \r\n",
    "                                sampling_rate=sampling_rate,\r\n",
    "                                batch_size=batch_size, \r\n",
    "                                overlap=overlap,\r\n",
    "                                length_output=output_length, \r\n",
    "                                gap=gap,\r\n",
    "                                stride=stride)\r\n",
    "batch_0 = data_gen[0]                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 10]\n",
      " [ 1 20]\n",
      " [ 2 30]\n",
      " [ 3 40]\n",
      " [ 4 50]] => 6\n",
      "[[ 1 20]\n",
      " [ 2 30]\n",
      " [ 3 40]\n",
      " [ 4 50]\n",
      " [ 5 60]] => 7\n",
      "[[ 2 30]\n",
      " [ 3 40]\n",
      " [ 4 50]\n",
      " [ 5 60]\n",
      " [ 6 70]] => 8\n",
      "[[ 3 40]\n",
      " [ 4 50]\n",
      " [ 5 60]\n",
      " [ 6 70]\n",
      " [ 7 80]] => 9\n",
      "[[ 4 50]\n",
      " [ 5 60]\n",
      " [ 6 70]\n",
      " [ 7 80]\n",
      " [ 8 90]] => 10\n",
      "[[  5  60]\n",
      " [  6  70]\n",
      " [  7  80]\n",
      " [  8  90]\n",
      " [  9 100]] => 11\n",
      "[[  6  70]\n",
      " [  7  80]\n",
      " [  8  90]\n",
      " [  9 100]\n",
      " [ 10 110]] => 12\n",
      "[[  7  80]\n",
      " [  8  90]\n",
      " [  9 100]\n",
      " [ 10 110]\n",
      " [ 11 120]] => 13\n",
      "[[  8  90]\n",
      " [  9 100]\n",
      " [ 10 110]\n",
      " [ 11 120]\n",
      " [ 12 130]] => 14\n",
      "[[  9 100]\n",
      " [ 10 110]\n",
      " [ 11 120]\n",
      " [ 12 130]\n",
      " [ 13 140]] => 15\n",
      "[[ 10 110]\n",
      " [ 11 120]\n",
      " [ 12 130]\n",
      " [ 13 140]\n",
      " [ 14 150]] => 16\n",
      "[[ 11 120]\n",
      " [ 12 130]\n",
      " [ 13 140]\n",
      " [ 14 150]\n",
      " [ 15 160]] => 17\n",
      "[[ 12 130]\n",
      " [ 13 140]\n",
      " [ 14 150]\n",
      " [ 15 160]\n",
      " [ 16 170]] => 18\n",
      "[[ 13 140]\n",
      " [ 14 150]\n",
      " [ 15 160]\n",
      " [ 16 170]\n",
      " [ 17 180]] => 19\n",
      "[[ 14 150]\n",
      " [ 15 160]\n",
      " [ 16 170]\n",
      " [ 17 180]\n",
      " [ 18 190]] => 20\n",
      "[[ 15 160]\n",
      " [ 16 170]\n",
      " [ 17 180]\n",
      " [ 18 190]\n",
      " [ 19 200]] => 21\n",
      "[[ 16 170]\n",
      " [ 17 180]\n",
      " [ 18 190]\n",
      " [ 19 200]\n",
      " [ 20 210]] => 22\n",
      "[[ 17 180]\n",
      " [ 18 190]\n",
      " [ 19 200]\n",
      " [ 20 210]\n",
      " [ 21 220]] => 23\n",
      "[[ 18 190]\n",
      " [ 19 200]\n",
      " [ 20 210]\n",
      " [ 21 220]\n",
      " [ 22 230]] => 24\n",
      "[[ 19 200]\n",
      " [ 20 210]\n",
      " [ 21 220]\n",
      " [ 22 230]\n",
      " [ 23 240]] => 25\n",
      "[[ 20 210]\n",
      " [ 21 220]\n",
      " [ 22 230]\n",
      " [ 23 240]\n",
      " [ 24 250]] => 26\n",
      "[[ 21 220]\n",
      " [ 22 230]\n",
      " [ 23 240]\n",
      " [ 24 250]\n",
      " [ 25 260]] => 27\n",
      "[[ 22 230]\n",
      " [ 23 240]\n",
      " [ 24 250]\n",
      " [ 25 260]\n",
      " [ 26 270]] => 28\n",
      "[[ 23 240]\n",
      " [ 24 250]\n",
      " [ 25 260]\n",
      " [ 26 270]\n",
      " [ 27 280]] => 29\n",
      "[[ 24 250]\n",
      " [ 25 260]\n",
      " [ 26 270]\n",
      " [ 27 280]\n",
      " [ 28 290]] => 30\n",
      "[[ 25 260]\n",
      " [ 26 270]\n",
      " [ 27 280]\n",
      " [ 28 290]\n",
      " [ 29 300]] => 31\n",
      "[[ 26 270]\n",
      " [ 27 280]\n",
      " [ 28 290]\n",
      " [ 29 300]\n",
      " [ 30 310]] => 32\n",
      "[[ 27 280]\n",
      " [ 28 290]\n",
      " [ 29 300]\n",
      " [ 30 310]\n",
      " [ 31 320]] => 33\n",
      "[[ 28 290]\n",
      " [ 29 300]\n",
      " [ 30 310]\n",
      " [ 31 320]\n",
      " [ 32 330]] => 34\n",
      "[[ 29 300]\n",
      " [ 30 310]\n",
      " [ 31 320]\n",
      " [ 32 330]\n",
      " [ 33 340]] => 35\n",
      "[[ 30 310]\n",
      " [ 31 320]\n",
      " [ 32 330]\n",
      " [ 33 340]\n",
      " [ 34 350]] => 36\n",
      "[[ 31 320]\n",
      " [ 32 330]\n",
      " [ 33 340]\n",
      " [ 34 350]\n",
      " [ 35 360]] => 37\n",
      "[[ 32 330]\n",
      " [ 33 340]\n",
      " [ 34 350]\n",
      " [ 35 360]\n",
      " [ 36 370]] => 38\n",
      "[[ 33 340]\n",
      " [ 34 350]\n",
      " [ 35 360]\n",
      " [ 36 370]\n",
      " [ 37 380]] => 39\n",
      "[[ 34 350]\n",
      " [ 35 360]\n",
      " [ 36 370]\n",
      " [ 37 380]\n",
      " [ 38 390]] => 40\n",
      "[[ 35 360]\n",
      " [ 36 370]\n",
      " [ 37 380]\n",
      " [ 38 390]\n",
      " [ 39 400]] => 41\n",
      "[[ 36 370]\n",
      " [ 37 380]\n",
      " [ 38 390]\n",
      " [ 39 400]\n",
      " [ 40 410]] => 42\n",
      "[[ 37 380]\n",
      " [ 38 390]\n",
      " [ 39 400]\n",
      " [ 40 410]\n",
      " [ 41 420]] => 43\n",
      "[[ 38 390]\n",
      " [ 39 400]\n",
      " [ 40 410]\n",
      " [ 41 420]\n",
      " [ 42 430]] => 44\n",
      "[[ 39 400]\n",
      " [ 40 410]\n",
      " [ 41 420]\n",
      " [ 42 430]\n",
      " [ 43 440]] => 45\n",
      "[[ 40 410]\n",
      " [ 41 420]\n",
      " [ 42 430]\n",
      " [ 43 440]\n",
      " [ 44 450]] => 46\n",
      "[[ 41 420]\n",
      " [ 42 430]\n",
      " [ 43 440]\n",
      " [ 44 450]\n",
      " [ 45 460]] => 47\n",
      "[[ 42 430]\n",
      " [ 43 440]\n",
      " [ 44 450]\n",
      " [ 45 460]\n",
      " [ 46 470]] => 48\n",
      "[[ 43 440]\n",
      " [ 44 450]\n",
      " [ 45 460]\n",
      " [ 46 470]\n",
      " [ 47 480]] => 49\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_gen)):\r\n",
    "    x, y = data_gen[i]\r\n",
    "    print('%s => %s' % (x.squeeze(), y.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = keras.preprocessing.sequence.TimeseriesGenerator(data, target, length=lags, batch_size=2)\r\n",
    "data_gen[-1][1]\r\n",
    "generator[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "44/44 [==============================] - 2s 11ms/step - loss: 112.0731 - mape: 21.2503\n",
      "Epoch 2/5\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.7332 - mape: 3.7708\n",
      "Epoch 3/5\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.6038 - mape: 3.2602\n",
      "Epoch 4/5\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.7527 - mape: 3.3513\n",
      "Epoch 5/5\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 4.4042 - mape: 5.6593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2372eaa4490>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\r\n",
    "model.add(\r\n",
    "    keras.layers.SimpleRNN(\r\n",
    "        100, \r\n",
    "        activation='relu', \r\n",
    "        input_shape=(lags, 2)))\r\n",
    "model.add(\r\n",
    "    keras.layers.Dense(\r\n",
    "        100, \r\n",
    "        activation='relu', \r\n",
    "        input_shape=(lags, 2)))\r\n",
    "model.add(\r\n",
    "    keras.layers.Dense(\r\n",
    "        50, \r\n",
    "        activation='relu', \r\n",
    "        input_shape=(lags, 2)))\r\n",
    "model.add(keras.layers.Dense(output_length))\r\n",
    "model.compile(optimizer='adam', loss=\"mse\",metrics='mape')\r\n",
    "model.fit(data_gen, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.914128 ],\n",
       "       [ 6.864224 ],\n",
       "       [ 7.8688483],\n",
       "       [ 8.907427 ],\n",
       "       [ 9.9184885],\n",
       "       [10.935935 ],\n",
       "       [12.051764 ],\n",
       "       [13.1500435],\n",
       "       [14.240685 ],\n",
       "       [15.323388 ],\n",
       "       [16.405249 ],\n",
       "       [17.489267 ],\n",
       "       [18.576496 ],\n",
       "       [19.664663 ],\n",
       "       [20.752834 ],\n",
       "       [21.841003 ],\n",
       "       [22.924736 ],\n",
       "       [24.001163 ],\n",
       "       [25.077589 ],\n",
       "       [26.15401  ],\n",
       "       [27.230442 ],\n",
       "       [28.306862 ],\n",
       "       [29.383291 ],\n",
       "       [30.459711 ],\n",
       "       [31.53614  ],\n",
       "       [32.612564 ],\n",
       "       [33.68899  ],\n",
       "       [34.76541  ],\n",
       "       [35.841835 ],\n",
       "       [36.91826  ],\n",
       "       [37.994698 ],\n",
       "       [39.071117 ],\n",
       "       [40.147545 ],\n",
       "       [41.22396  ],\n",
       "       [42.30039  ],\n",
       "       [43.37682  ],\n",
       "       [44.453247 ],\n",
       "       [45.529667 ],\n",
       "       [46.606102 ],\n",
       "       [47.682507 ],\n",
       "       [48.75895  ],\n",
       "       [49.83536  ],\n",
       "       [50.911797 ],\n",
       "       [51.98823  ]], dtype=float32)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52035e4d146f99c150422bfac8e07f32a30b89a60d9dd60756d600c4b026426f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}